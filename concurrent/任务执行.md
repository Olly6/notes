## 任务执行
在服务器应用程序中，串行处理机制通常无法提供高吞吐率或者快速响应性。

在正常负载情况下，“为每个任务分配一个线程”的方法能提升串行的性能，但是这种方法存在一些缺陷，尤其是当需要创建大量的线程时：

* **线程生命周期的开销非常高**。 线程的创建与销毁并不是没有代价的。线程的创建过程都需要时间，延迟处理的请求，并且需要JVM和操作系统提供一些辅助操作。
* **资源消耗**。活跃的线程会消耗系统资源，尤其是内存。如果可运行的线程数量多于可用处理器的数量，那么有些线程将会闲置。大量空闲的线程会占用许多内存，给垃圾回收带来压力，而且大量线程在竞争CPU资源时还将产生其他的性能开销。
* **稳定性**。在一定的范围内，增加线程可以提高系统的吞吐量，但是如果超出了这个范围，再创建更多的线程只会降低程序的执行速度，并且如果过多地创建一个线程，那么整个应用程序将会崩溃。

#### Executor框架
在java类库中，任务执行的主要抽象不是Thread而是Executor。

```
public interface Executor {
	void execute(Runnable command);
}
```
它提供了一种标准的方法将任务的提交过程与执行过程解耦开来，并用Runnable来表示任务。Executor的实现还提供了对生命周期的支持，以及统计信息收集、应用程序管理机制和性能监视等机制。

Executor基于生产者-消费者模式，提交任务的操作相当于生产者，执行任务的相当于消费者。如果要在程序中实现一个生产者-消费者的设计，那么最简单的方式通常就是使用Executor。

```
public class TaskExecutionWebServer {
    private static final int NTHREADS = 100;
    private static final Executor exe = Executors.newFixedThreadPool(NTHREADS);

    public static void main(String[] args) {
        while (true){
            Runnable runnable = new Runnable() {
                @Override
                public void run() {
                    //do something
                }
            };
            exe.execute(runnable);
        }
    }
}
```
上面的代码就是请请求处理任务的提交与任务的实际执行解耦。

每当看到下面的代码时候，

```
new Thread(runnable).start();
```
并且你希望获得一种更灵活的执行策略时，请考虑使用Executor来代替Thread.

#### 线程池
线程池是与工作队列（Work Queue）密切相关的，其中在工作队列中保存了所有等待执行的任务。工作者线程（Work Thread）的任务很简单：从工作队列中获取一个任务，执行任务，然后返回线程池并等待下一个任务。

“在线程池中执行任务”比“为每一个任务分配一个线程”优势更多。通过重用现有的线程还不是创建新线程，可以在处理多个请求时分摊在线程创建和销毁过程中产生的巨大开销。另一个额外的好处是，当请求到达时，工作线程通常已经存在，因此不会由于等待创建线程而延迟任务的执行，从而提高了响应性。

可以通过调用Executors中的讲台工厂方法之一来创建一个线程池：

* newFixedThreadPool.它会创建一个固定长度的线程池，每当提交一个任务时就创建一个线程，知道达到线程池的最大数量，这时线程池的规模将不再变化（如果某个线程由于发生了未预期的Exception而结束，那么线程池会补充一个新的线程）；
* newCachedThreadPool。将创建一个可以缓存的线程池，如果线程池的当前规模超过了处理需求时，那么将回收空闲的线程，而当需求增加时，则可以添加新的线程，线程池的规模不存在限制。
* newSingleThreadExecutor。是一个单线程的Executor，它创建单个工作者线程来执行任务，如果这个线程异常结束，会创建另一个线程来替补。newSIngleThreadExecutor能确保依照任务在队列中的顺序来串行执行（FIFO,LIFO,优先级）。
* newScheduledThreadPool。创建一个固定长度的线程池，而且以延迟或定时的方式来执行任务。

**newFixedThreadPool和newCacheedThreadPool这两个工厂方法返回的通用的ThreadPoolExecutor实例，这些实例可以直接用来构造专门用途的executor**

好处：
从“为每个任务分配一个线程”策略编程基于线程池的策略，将对应用程序的稳定性产生重大影响：web服务器不会再在高负载情况下失败。由于服务器不会创建数千个线程来争夺有限的CPU和内存资源，因此服务器的性能将平缓的降低。

Executor的实现通常会创建线程来执行任务。但JVM只有在所有(非守护)线程全部终止后才会退出。因此，如果无法正确的关闭Executor那么JVM将无法结束。

由于Executor是以异步方式来执行任务，因此之前提交任务的状态不是立即可见的。

为了解决执行服务的生命周期，Executor扩展了ExecutorService接口。

```
public interface ExecutorService extends Executor{
	void shutdown();
	List<Runnable> shutdownNow();
	boolean isShutdown();
	boolean isTerminated();
	boolean awaitTermination(long timeout,TimeUnit unit);
}
```
shutdown将执行平缓的关闭过程：不再接受新任务，而同时等待以及提交的任务完成-包括那些还未开始执行的任务。
shutdownNow方法将执行粗暴的关闭过程：它将试图取消所有运行中的任务，并且不再启动队列中尚未开始执行的任务。

如果要构建自己的调度服务，那么可以使用DelayQueue,它实现了BlockingQueue，并且为ScheduledThreadPoolExecutor提供调度功能。

#### 中断
如果任务调用了一个阻塞方法，例如BlockingQueue.put，那么可能会产生一个更严重的问题--任务可能永远不会检查取消标志，因此永远不会结束。因为，如果生产者的速度超过了消费者的处理速度，队列将被填满，put方法也会阻塞。当生产者在put方法中阻塞时，如果消费者希望取消生产者任务，那么将发生什么情况？它可以调用cancel方法来设置cancelled标志，但此时生产者却永远不能检查这个标志，因为它无法从阻塞的put方法中恢复过来。这个时候就需要线程中断。

**线程中断：**它并不会真正的中断一个正在运行的线程，而只是发出中断请求，然后由线程在下一个合适的时刻中断自己。有些方法，例如wait、sleep和join等，将严格的处理这种请求，当它们收到中断请求或者在开始执行时发现某个已经被设置好的中断状态时，将抛出一个异常。设计良好的方法可以完全忽略这种请求，只要它们在调用代码对中断请求进行某种处理。设计糟糕的方法可能会屏蔽中断请求，从而导致调用栈中的其他代码无法对中断请求做出响应。

在使用静态的interrupted时应该小心，因为它会清除当前线程的中断状态。如果在调用interrupted时返回true，那么除非你想屏蔽这个中断，否则必须对它处理--可以抛出interruptedException，或者通过再次调用interrupt来恢复中断状态。

**通常，中断是实现取消的最合理方式。**

#### 通过future来实现取消
ExecutorService.submit将返回一个future来描述任务。执行任务的线程是由标准的executor创建的，它实现了一种中断策略可以通过中断被取消，那么可以设置mayInterruptIfRunning.

**当Future.get抛出InterruptedException或者TimeoutException时，如果你知道不再需要结果，那么久可以调用Future.cancel来取消任务**

#### 线程的创建与销毁
ThreadPoolExecutor允许提供一个BlockingQueue来保存等待执行的任务。基本的任务排队方法有3种：无界队列、有界队列和同步移交（synchronous）

* newFixedThreadPool和newSingleThreadExecutor在默认情况下将使用一个无界的linkedBlockingQueue，如果所有工作者线程都处于忙碌状态，那么任务将在队列中等候。如果任务持续快速的到达，并且超过了线程池处理他们的速度，那么队列将无限的增加。

一种更稳妥的资源管理策略是使用有界队列，例如ArrayBlokingQueue、有界的linkedblockingQueue、PriorityBlockingQueue。**有界队列有助于避免资源耗尽的情况发生，但它又带来了新的问题：当队列填满后，in的任务该怎么办？【参看饱和策略】在使用有界的工作队列时，队列的大小与线程池的大小必须一起调节。如果线程池较小而队列较大，那么有助于减少内存使用量，降低cpu的使用率，同时还可以减少上下文切换，但是付出的代价可能会限制吞吐量。**

对于非常大的或者无界的线程池，可以通过synchronousQueue来避免任务排队，以及直接将任务宠生产者移交给工作者线程。synchronousQueue不是一个真正的队列，而是一直在线程之间进行移交的机制。将一个元素放入SynchronousQueue中，必须有一个另一个线程在等待接收这个元素。如果没有线程正在等待，并且线程池的当前大小小于最大值，那么ThreadPoolExecutor将创建一个新的线程，否则根据饱和策略，这个任务将被拒绝。只有当线程池是无界的或者可以拒绝任务时候才可以使用。

#### 饱和策略
AbrotPolicy callerRunsPolicy DiscardPolicy 和DiscardOldestPolicy

AbrotPolicy（中止）这是默认的饱和策略，抛出异常，调用者可以捕获，然后根据需求编写自己的处理代码。

discard抛弃

调用者运行(caller-runs)策略实现了一种调节机制，该策略既不会抛弃任务，也不会抛出异常，而是将任务回退到调用者。

### 死锁
我们使用加锁机制来确保线程安全，但是如果过度使用加锁，则可能导致锁顺序死锁。同样，我们使用线程池和信号量来限制对资源的使用，但这些限制的行为可能会导致资源死锁。

#### 锁顺序死锁
死锁的原因：两个线程试图以不同的顺序来获得相同的锁。

如果按照相同的锁顺序来请求锁，那么就不会出现循环的加锁依赖性。

```
public class LeftRightDeadLock{
	private final Object left = new Object();
	private final Object right = new Object();
	
	public void leftRight(){
		synchoronized(left){
			synchronized(right){
				doSth();
			}
		}
	}
	
	public void rightLeft(){
		synchoronized(right){
			synchronized(left){
				doSth();
			}
		}
	}
}
```
还有动态的锁顺序死锁

#### 开放调用
如果在调用某个方法时不需要持有锁，那么这种调用称为开放调用(Open Call)。同步块代码仅被用于保护那些涉及共享状态的操作。

#### 资源死锁
假设有两个资源池，例如两个不同数据库的连接池。资源池通常采用信号量来实现当资源池为空时的阻塞行为。如果一个任务需要连接两个数据库，并且在请求时候不遵循相同的顺序，那么A可能持有D1等待D2 B有可能持有D2等待D1，发生死锁。

另一种基于资源的死锁形式就是线程饥饿死锁。如果一个任务提交另一个任务，并等待被提交任务在单线程的executor中执行完成。这种情况下，第一个任务将永远等待下去，并使得另一个任务以及在这个Executor中执行的所有其他任务都停止执行。如果某些任务需要等待其他任务的结果，那么这些任务就是产生线程饥饿死锁的主要来源。

#### 如何避免死锁
* 支持定时的锁：有一项技术可以检测死锁和从死锁中恢复过来，即显式使用Lock类中的定时tryLock功能。当使用内置锁，只要没有获得锁，就会永远等待下去，而显式锁则可以定制一个超时时限。
* 通过使用thread Dump来分析死锁：JVM可以使用Thread Dump来帮助识别死锁的发生。

#### 活锁
活锁尽管不会阻塞线程，但也不能继续执行，因为线程将不断重复执行相同的操作，而且总会失败。活锁通常发生在处理事务消息的应用程序中：如果不能成功的处理某个消息，那么消息处理机制将回滚整个事务，并将它重新放入队列的开头。

要解决这种活锁问题，需要再