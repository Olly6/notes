# 大规模分布式存储系统
## 1.分布式存储概念
* 可扩展。分布式存储系统可以扩展到几百台甚至几千台的集群规模，而且，随着集群规模的正在，系统整体性能表现为线性增长。
* 低成本。分布式存储系统的自动容错、自动负载均衡机制使其可以构建在普通PC机智商。另外，线性扩展能力也使得增加、减少机器非常方便，可以实现自动运维
* 高性能。无论是针对整个集群还是单台服务器，都要求分布式存储系统具备高性能。
* 易用。分布式存储系统需要能够提供易用的对外接口，另外，也要求具备完善的监控、运维工具，并能够方便地与其他系统集成。

分布式存储系统的挑战主要在于数据、状态信息的持久化，要求在自动迁移、自动容错、并发读写的过程中保证数据的一致性。

## 2.并发控制
### 1.数据库锁
事务分为几种类型：读事务，写事务以及读写混合事务。相应的锁也分为两种类型：读锁以及写锁，允许对同一个元素加多个读锁，但只允许加一个写锁，且写事务将阻塞读事务。

解决死锁的思路主要有两种：第一种是为每个事务设置一个超时时间，超时后自动回滚。
第二种思路是死锁检测。死锁出现的原因在于事务之间互相依赖，依赖关系构成一个环路。检测到死锁后可以通过回滚其中某些事务来消除循环依赖。

### 2.写时复制
互联网业务中读事务所占的比例往往超过写事务，很多应用的读写比例达到6:1甚至10:1，写时复制(Copy-On-Write)，读操作不用加锁，极大地提高了读性能。

写时复制B+树执行写操作步骤如下：

1）copy：将从叶子到根节点路径上的所有节点copy出来

2）修改：对copy的节点执行修改。

3）提交：原子的切换根节点的指针，使之指向新的根节点

如果读操作发生在第3步提交之前，那么将读取老节点的数据，否则将读取新节点。读操作不需要加锁。写时复制设计引用计数，对每个节点维护一个引用计数，表示被多少节点引用，如果引用计数变为0，说明没有节点引用，可以被垃圾回收。

写时复制技术原理简单，问题是每次写操作都需要copy从叶子到根节点路径上的所有节点，写成本高，另外，多个写操作之间是互斥的，同一时刻只允许一个写操作。

### 3.MVCC 多版本并发控制
MVCC对每行数据维护多个版本，无论事务的执行时间多长，MVCC总是能够提供与事务开始时刻相一致的数据。

InnoDB存储引擎为例，InnoDB对每一行都维护了两个隐藏的列，其中一列存储被修改的“时间”，另外一列存储行被删除的“时间”，这里存储的是与时间对于的数据库系统的版本号，每当一个事务开始时，InnoDB都会给这个事务分配一个递增的版本号，所以版本号也可以认为是事务号。

**可以参考高性能mysql来完成**

## 3.故障恢复
数据库运行过程中可能会发生故障，这个时候某些事务可能执行到一半但没有提交，当系统重启时，需要能够恢复到一致的状态，即要么提交整个事务，要么回滚。

数据库系统以及其他的分布式存储系统一般采用操作日志(有时也称为提交日志 commit log)技术来实现故障恢复。操作日志分为回滚日志（UNDO Log）、重做日志(REDO Log)以及UNDO/REDO日志。如果记录事务修改前的状态，则为回滚日志，相应的如果记录事务修改后的状态，则为重做日志。

**可以参考mysql的操作日志、重做日志的话redis的AOF就可以，都是采用追加的的方式写入磁盘日志文件**


## 4数据分布
分布式系统区别与传统单机系统在于能够将数据分布到多个节点，并在多个节点之间实现负载均衡。数据分布的方式主要有两种：一种是哈希分布，如一致性哈希。另一种就是顺序分布，即每张表格上的数据按照主键整体有序。

### 4.1哈希分布
哈希取摸的方法很常见，其方法是根据数据的的某一种特征计算hash值，并将hash值与集群中的服务器建立映射关系，从而将不同哈希值分不到不同的服务器上。

**一致性hash**
假设hash空间为0~2^n,一致性哈希算法如下：

* 首先求出每个服务器的hash值，将其配置到一个0~2^n的圆环区间上
* 其次使用同样的方法求出待存储对象的主键hash值，也将其配置到这个圆环上。
* 然后从数据映射的位置开始顺时针查找，将数据分布到找到的第一个服务器节点。

### 4.2顺序分布
hash散列破坏了数据的有序性，只支持随机读取操作，不能够支持顺序扫描。
顺序分布在分布式表格系统中比较常见，一般的做法是将大表划分为连续的范围，每个范围称为一个子表，总控服务器负责将这些子表安装一定的策略分配到存储节点上。顺序分布与B+树结构比较类似，每个子表相当于叶子节点。 

### 4.3负载均衡
分布式存储系统的每个集群中一般有一个总控节点，其他节点为工作节点，由总控节点根据全局负载信息进行整体调度。工作节点刚上线时，总控节点需要将数据迁移到改节点，另外，系统运行过程中也需要不断的执行迁移任务，将数据从负载较高的节点迁移到负载较低的工作节点。

工作节点通过心跳包（heartBeat,定时发送）将节点负载相关的信息，如CPU、内存、磁盘、网络等

## 5.复制
为了保证分布式存储系统的高可靠和高可用，数据在系统中一般存储多个副本。当某个副本所在的存储节点出现故障时，分布式存储系统能够自动将服务器切换到其他的副本，从而实现自动容错。分布式存储系统通过复制协议将数据同步到多个存储节点，并确保多个副本之间的数据一致性。

同一份数据的多个副本中往往有一个副本为主副本(primary)，其他副本为备副本(backup)，由主副本将数据复制到备份副本。复制协议分为两种，强同步复制以及异步复制，二者的区别在于用户的写请求是否需要同步到备副本才可以返回成功。假如备副本不止一个，复制协议还会要求写请求至少需要同步到几个备副本。当主副本出现故障时，分布式存储系统能够将服务自动切换到某个备副本，实现自动容错。


一致性和可用性是矛盾的，强同步复制协议可以保证主备副本之间的一致性，但是当备副本出现故障时，也可能阻塞存储系统的正常写服务，系统的整体可用性收到影响；异步复制协议的可用性相对较好，但是一致性得不到保障，主副本出现故障时还有数据丢的可能。

### 5.1复制概述
强同步和异步复制都是将主副本的数据以某种形式发送到其他副本，这种协议称为基于主副本的复制协议（primary-based protocol）。这种方法要求在任何时候只能有一个副本为主副本，由它来确定写操作之间的顺序。如果主副本出现故障，需要选举出一个备副本成为新的主副本。经典的协议paxos

### 5.2 一致性与可用性
CAP理论：一致性(Consistency)、可用性(Availability)、分区容错性(P) 三者不能同时满足，但是P必须是要的。

## 6.容错
容错是分布式存储系统的重要目标，只有实现了自动化容错，才能减少人工运维成本，实现分布式存储的规模效应。
首先分布式系统需要能够检测到机器故障，在分布式系统中，故障检测往往通过租约(lease)协议实现。接着，需要能够将服务复制或者迁移到集群中的其他正常服务的节点。

* 1.常见故障
	单机故障和磁盘故障发生概率最高，几乎每天都有多起事故发生。系统设计首先需要对单台服务器故障进行容错处理。一般来说，分布式存储系统会保存多分数据，当其中一份数据所在服务器发生故障时，能通过其他副本继续提供服务。另外，机架故障发生的概率相对也是比较高的，需要避免将数据的所有副本都分布在同一个机架内。最后，还可能出现磁盘响应慢，内存错误，机器配置错误，数据中心网络连接不稳定等。
* 2故障检测
容错处理的第一步是故障检测，心跳是一种很自然的想法。总控机A每隔一秒向工作机B发送一个心跳包。如果一切正常，机器B会相应A的心跳包，否则，机器A重试一定次数认为B发生了故障。然后机器A接不到机器B的心跳并不能确保机器B发生了故障并停止了服务。可能网络不通可能系统繁忙无法响应等，由于机器B发生故障后，往往需要将它上面的服务迁移到集群中的其他服务器，为了保证一致性，需要确保B不再提供服务，否则将出现多台服务器同时服务同一份数据而导致数据不一致。

可以通过租约(lease)机制进行故障检测。租约机制就是带有超时时间的一种授权。假设A需要检测B是否发生故障，机器A可以给B发放租约，机器B持有的租约在有效期内才允许提供服务，否则主动停止服务。机器B的租约快要到期的时候向机器A重新申请租约。正常情况下机器B通过不断申请租约来延长有效期，当机器B出现故障或者与机器A之间的网络发生故障时，机器B的租约将过期，从而机器A能够确保机器B不再提供服务，机器B的服务器可以被安全的迁移到其他服务器。
因为时钟问题，实现租约机制需要考虑一个提前量。如果机器B的租约有效期为10秒，那么机器A需要加上一个提前量，比如11秒才可以认为机器B租约到期。